{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fa2e13-567d-4509-9023-c99fb230f31f",
   "metadata": {},
   "source": [
    "# Lesson 2 : LangGraph Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json, re\n",
    "import pprint\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "# import local modules\n",
    "dir_current = os.path.abspath('')\n",
    "dir_parent = os.path.dirname(dir_current)\n",
    "if dir_parent not in sys.path:\n",
    "    sys.path.append(dir_parent)\n",
    "from utils import utils\n",
    "\n",
    "# Set basic configs\n",
    "logger = utils.set_logger()\n",
    "pp = utils.set_pretty_printer()\n",
    "\n",
    "# Set main parameters\n",
    "tavily_api_key_name = \"TAVILY_API_KEY\"\n",
    "aws_region = \"us-east-1\"\n",
    "\n",
    "# Set bedrock configs\n",
    "bedrock_config = Config(\n",
    "    connect_timeout=120, read_timeout=120, retries={\"max_attempts\": 0}\n",
    ")\n",
    "\n",
    "# Create a bedrock runtime client\n",
    "bedrock_rt = boto3.client(\n",
    "    \"bedrock-runtime\",\n",
    "    region_name=aws_region,\n",
    "    config=bedrock_config\n",
    ")\n",
    "\n",
    "# Create a bedrock client to check available models\n",
    "bedrock = boto3.client(\n",
    "    \"bedrock\",\n",
    "    region_name=aws_region,\n",
    "    config=bedrock_config\n",
    ")\n",
    "\n",
    "# Retrieve API KEY from env variables or secrets manager\n",
    "try:\n",
    "    tavily_ai_api_key = utils.get_from_secretstore_or_env(tavily_api_key_name, aws_region)\n",
    "    os.environ[\"TAVILY_API_KEY\"] = tavily_ai_api_key\n",
    "except ValueError as ve:\n",
    "    logger.error(\n",
    "        \"Could not retrieve the TAVILIY API KEY, neither from the os enviroment variables, nor from AWS Secrets manager!\"\n",
    "    )\n",
    "    logger.error(ve)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=4)  # increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196c186-af55-4f2d-b569-b7d63a859304",
   "metadata": {},
   "source": [
    "> If you are not familiar with python typing annotation, you can refer to the [python documents](https://docs.python.org/3/library/typing.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7ba73-e603-453b-b06f-5db92c567b19",
   "metadata": {},
   "source": [
    "> Note: in `take_action` below, some logic was added to cover the case that the LLM returned a non-existent tool name. Even with function calling, LLMs can still occasionally hallucinate. Note that all that is done is instructing the LLM to try again! An advantage of an agentic organization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 727
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_bedrock)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\", self.exists_action, {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile()\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state[\"messages\"][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_bedrock(self, state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {\"messages\": [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t[\"name\"] in self.tools:  # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t[\"name\"]].invoke(t[\"args\"])\n",
    "            results.append(\n",
    "                ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(result))\n",
    "            )\n",
    "        print(\"Back to the model!\")\n",
    "        return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatBedrockConverse(\n",
    "    client=bedrock_rt,\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    ")\n",
    "\n",
    "abot = Agent(model, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6f5f4-2392-41b9-ab96-7919840baa3e",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "#make sure to install pygraphviz if you haven't done so already using 'conda install --channel conda-forge pygraphviz'\n",
    "from IPython.display import Image\n",
    "Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a06a8c-fcd4-4ca6-98f0-36c5809813e6",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and LA?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "# Note, the query was modified to produce more consistent results.\n",
    "# Results may vary per run and over time as search information and models change.\n",
    "\n",
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\"\n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "model = ChatBedrockConverse(\n",
    "    client=bedrock_rt,\n",
    "    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    ")\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
